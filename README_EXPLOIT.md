# vLLM Assert 漏洞利用工具使用说明

## 概述

本工具是针对vLLM项目中assert语句漏洞的概念验证(PoC)脚本。通过发送特定构造的请求，可以触发vLLM服务器中的AssertionError，导致服务崩溃或异常响应。

## 漏洞背景

vLLM项目在多个关键位置使用了assert语句进行条件检查，这些assert在生产环境中可能成为攻击向量：

1. **Logprobs Assert** - 当请求logprobs但服务器未返回时触发
2. **Max_tokens Assert** - 当max_tokens字段为None但代码期望非None时触发
3. **Final_res Assert** - 当生成器未返回结果时触发
4. **Generators Assert** - 当生成器数量不符合预期时触发

## 安装要求

```bash
pip install requests
```

## 使用方法

### 基本使用

```bash
# 测试本地vLLM服务器
python vllm_assert_exploit.py

# 测试远程服务器
python vllm_assert_exploit.py http://example.com:8000

# 设置超时时间
python vllm_assert_exploit.py --timeout 30 http://example.com:8000
```

### 高级选项

```bash
# 启用详细输出
python vllm_assert_exploit.py --verbose http://example.com:8000

# 查看帮助
python vllm_assert_exploit.py --help
```

## 测试项目

工具包含以下7个测试项目：

### 1. logprobs_assert
- **目标**: 触发`assert output.logprobs is not None`
- **方法**: 发送设置了`logprobs=True`和`top_logprobs=1`的请求
- **风险**: 高 - 容易触发，直接导致服务崩溃

### 2. streaming_logprobs_assert
- **目标**: 在流式响应中触发logprobs assert
- **方法**: 发送流式请求并启用logprobs
- **风险**: 高 - 可能导致流式连接中断

### 3. max_tokens_assert
- **目标**: 触发`assert request.max_tokens is not None`
- **方法**: 发送缺少max_tokens字段的completion请求
- **风险**: 高 - 在特定代码路径中必然触发

### 4. max_tokens_none_assert
- **目标**: 通过显式设置max_tokens为None触发assert
- **方法**: 发送max_tokens=None的请求
- **风险**: 中 - 需要特定的请求格式

### 5. combined_assert_attack
- **目标**: 组合多个assert触发条件
- **方法**: 发送包含多个异常参数的复杂请求
- **风险**: 高 - 增加触发概率

### 6. final_res_assert
- **目标**: 触发`assert final_res is not None`
- **方法**: 发送可能导致生成器返回None的请求
- **风险**: 中 - 需要特定的服务器状态

### 7. concurrent_assert
- **目标**: 通过并发请求触发竞态条件
- **方法**: 同时发送多个可能触发assert的请求
- **风险**: 中 - 可能导致服务器不稳定

## 输出解释

### 正常输出
```
[+] Server is available, starting exploit tests...
[*] Testing logprobs assert vulnerability...
[+] Response status: 200
[+] Request succeeded (no assert triggered)
[+] logprobs_assert: Not vulnerable
```

### 发现漏洞
```
[*] Testing logprobs assert vulnerability...
[+] Response status: 500
[!] Potential assert failure detected!
[!] CONFIRMED: AssertionError detected!
[!] Response snippet: {"error":{"message":"AssertionError: Did not output logprobs"...
[!] logprobs_assert: VULNERABLE!
```

### 测试总结
```
============================================================
SUMMARY:
============================================================
logprobs_assert               : VULNERABLE
streaming_logprobs_assert     : Safe
max_tokens_assert            : VULNERABLE
max_tokens_none_assert       : Safe
combined_assert_attack       : Safe
final_res_assert             : Safe
concurrent_assert            : Safe

Total: 2/7 tests found vulnerabilities

[!] WARNING: Server appears to be vulnerable to assert-based attacks!
[!] These vulnerabilities can lead to service disruption.
```

## 实际攻击场景

### 1. 服务拒绝攻击(DoS)
```bash
# 持续发送触发assert的请求
while true; do
    python vllm_assert_exploit.py http://target:8000
    sleep 1
done
```

### 2. 服务探测
```bash
# 通过assert响应判断服务器类型和版本
python vllm_assert_exploit.py http://target:8000 | grep "VULNERABLE"
```

### 3. 批量测试
```bash
# 测试多个服务器
for server in server1:8000 server2:8000 server3:8000; do
    echo "Testing $server"
    python vllm_assert_exploit.py http://$server
done
```

## 防护建议

### 立即修复
1. 将所有assert语句替换为显式的条件检查
2. 使用适当的异常处理机制
3. 避免在生产环境中暴露内部错误信息

### 代码修复示例
```python
# 原代码 (有漏洞)
assert output.logprobs is not None, "Did not output logprobs"

# 修复后
if output.logprobs is None:
    logger.error("Did not output logprobs")
    return self.create_error_response("Internal error: logprobs not available")
```

### 长期改进
1. 建立统一的错误处理机制
2. 实施输入验证和边界检查
3. 添加请求频率限制
4. 实施异常监控和告警

## 检测方法

### 日志监控
```bash
# 监控AssertionError
grep -i "assertionerror" /var/log/vllm/*.log

# 监控500错误
grep "500" /var/log/nginx/access.log | grep -i "chat/completions"
```

### 系统监控
```bash
# 监控服务器重启
systemctl status vllm-server

# 监控内存使用
top -p $(pgrep vllm)
```

## 免责声明

本工具仅用于安全研究和漏洞测试目的。使用者应当：

1. 仅在授权的环境中使用
2. 不得用于恶意攻击或破坏
3. 遵守相关法律法规
4. 负责任地披露发现的漏洞

## 技术细节

### Assert语句位置
- `vllm/entrypoints/openai/serving_chat.py:586, 975` - logprobs检查
- `vllm/entrypoints/openai/serving_completion.py:370, 508` - max_tokens检查  
- `vllm/entrypoints/openai/serving_chat.py:965, 1129` - final_res检查
- `vllm/entrypoints/openai/serving_chat.py:270` - generators数量检查

### 触发条件
1. **Logprobs Assert**: `logprobs=True` + `top_logprobs>0` + 服务器未返回logprobs
2. **Max_tokens Assert**: `max_tokens=None` + 启用echo模式
3. **Final_res Assert**: 生成器异常或超时
4. **Generators Assert**: 生成器数量不等于1

### 影响评估
- **可用性**: 服务崩溃或异常响应
- **完整性**: 可能导致数据处理错误
- **机密性**: 可能泄露内部错误信息

## 更新日志

- v1.0 - 初始版本，包含7个测试项目
- 支持自定义超时和详细输出
- 添加并发测试和组合攻击